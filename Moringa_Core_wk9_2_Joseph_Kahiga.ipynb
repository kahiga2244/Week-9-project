{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moringa_Core_wk9_2_Joseph_Kahiga.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEYXPf7/hC8svSjLud/v3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kahiga2244/Week-9-project/blob/master/Moringa_Core_wk9_2_Joseph_Kahiga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWIqcCg-tBgd",
        "colab_type": "text"
      },
      "source": [
        "1.Defining the question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCyOlKfutVjZ",
        "colab_type": "text"
      },
      "source": [
        "a) Specifying the Data Analytic Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vhf3LEntHsT",
        "colab_type": "text"
      },
      "source": [
        "For dataset 2, perform classification of the testing set samples using the Naive Bayes Classifier.\n",
        "Compute the accuracy (percentage of correct classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flcYGGabtZ4u",
        "colab_type": "text"
      },
      "source": [
        "b. Metric of success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yHJZXbStc4z",
        "colab_type": "text"
      },
      "source": [
        "Compute the accuracy (percentage of correct classification).\n",
        "Report the confusion matrix of each classifier.\n",
        "Repeat step 2 to step 4 twice, each time splitting the datasets differently i.e. 70-30, 60-40, then note the outcomes of your modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_QWUOEatkk_",
        "colab_type": "text"
      },
      "source": [
        "c) Understanding the context\n",
        "\n",
        "d) Recording the Experimental Design\n",
        "\n",
        "e) Data Relevance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxGRMmJWygEX",
        "colab_type": "text"
      },
      "source": [
        "2. Loading the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q5MSJREfvdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BbmtEvfylyL",
        "colab_type": "text"
      },
      "source": [
        "b. loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bioAIoovyRUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/spambase_csv.csv')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5EdMT67yXcl",
        "colab_type": "text"
      },
      "source": [
        "3. checking the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5WAK1AfyoVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "a95cced8-3104-41b6-f460-fdaa233ab2af"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_%3B</th>\n",
              "      <th>char_freq_%28</th>\n",
              "      <th>char_freq_%5B</th>\n",
              "      <th>char_freq_%21</th>\n",
              "      <th>char_freq_%24</th>\n",
              "      <th>char_freq_%23</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word_freq_make  word_freq_address  ...  capital_run_length_total  class\n",
              "0            0.00               0.64  ...                       278      1\n",
              "1            0.21               0.28  ...                      1028      1\n",
              "2            0.06               0.00  ...                      2259      1\n",
              "3            0.00               0.00  ...                       191      1\n",
              "4            0.00               0.00  ...                       191      1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMtRR8mkyqB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "39bf854b-c291-41cf-a706-d4dcf711cead"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_%3B</th>\n",
              "      <th>char_freq_%28</th>\n",
              "      <th>char_freq_%5B</th>\n",
              "      <th>char_freq_%21</th>\n",
              "      <th>char_freq_%24</th>\n",
              "      <th>char_freq_%23</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word_freq_make  word_freq_address  ...  capital_run_length_total  class\n",
              "4596            0.31                0.0  ...                        88      0\n",
              "4597            0.00                0.0  ...                        14      0\n",
              "4598            0.30                0.0  ...                       118      0\n",
              "4599            0.96                0.0  ...                        78      0\n",
              "4600            0.00                0.0  ...                        40      0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdie2oaSyrqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da303bda-d7f1-4180-8a6d-d80a69b07a0e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   word_freq_make              4601 non-null   float64\n",
            " 1   word_freq_address           4601 non-null   float64\n",
            " 2   word_freq_all               4601 non-null   float64\n",
            " 3   word_freq_3d                4601 non-null   float64\n",
            " 4   word_freq_our               4601 non-null   float64\n",
            " 5   word_freq_over              4601 non-null   float64\n",
            " 6   word_freq_remove            4601 non-null   float64\n",
            " 7   word_freq_internet          4601 non-null   float64\n",
            " 8   word_freq_order             4601 non-null   float64\n",
            " 9   word_freq_mail              4601 non-null   float64\n",
            " 10  word_freq_receive           4601 non-null   float64\n",
            " 11  word_freq_will              4601 non-null   float64\n",
            " 12  word_freq_people            4601 non-null   float64\n",
            " 13  word_freq_report            4601 non-null   float64\n",
            " 14  word_freq_addresses         4601 non-null   float64\n",
            " 15  word_freq_free              4601 non-null   float64\n",
            " 16  word_freq_business          4601 non-null   float64\n",
            " 17  word_freq_email             4601 non-null   float64\n",
            " 18  word_freq_you               4601 non-null   float64\n",
            " 19  word_freq_credit            4601 non-null   float64\n",
            " 20  word_freq_your              4601 non-null   float64\n",
            " 21  word_freq_font              4601 non-null   float64\n",
            " 22  word_freq_000               4601 non-null   float64\n",
            " 23  word_freq_money             4601 non-null   float64\n",
            " 24  word_freq_hp                4601 non-null   float64\n",
            " 25  word_freq_hpl               4601 non-null   float64\n",
            " 26  word_freq_george            4601 non-null   float64\n",
            " 27  word_freq_650               4601 non-null   float64\n",
            " 28  word_freq_lab               4601 non-null   float64\n",
            " 29  word_freq_labs              4601 non-null   float64\n",
            " 30  word_freq_telnet            4601 non-null   float64\n",
            " 31  word_freq_857               4601 non-null   float64\n",
            " 32  word_freq_data              4601 non-null   float64\n",
            " 33  word_freq_415               4601 non-null   float64\n",
            " 34  word_freq_85                4601 non-null   float64\n",
            " 35  word_freq_technology        4601 non-null   float64\n",
            " 36  word_freq_1999              4601 non-null   float64\n",
            " 37  word_freq_parts             4601 non-null   float64\n",
            " 38  word_freq_pm                4601 non-null   float64\n",
            " 39  word_freq_direct            4601 non-null   float64\n",
            " 40  word_freq_cs                4601 non-null   float64\n",
            " 41  word_freq_meeting           4601 non-null   float64\n",
            " 42  word_freq_original          4601 non-null   float64\n",
            " 43  word_freq_project           4601 non-null   float64\n",
            " 44  word_freq_re                4601 non-null   float64\n",
            " 45  word_freq_edu               4601 non-null   float64\n",
            " 46  word_freq_table             4601 non-null   float64\n",
            " 47  word_freq_conference        4601 non-null   float64\n",
            " 48  char_freq_%3B               4601 non-null   float64\n",
            " 49  char_freq_%28               4601 non-null   float64\n",
            " 50  char_freq_%5B               4601 non-null   float64\n",
            " 51  char_freq_%21               4601 non-null   float64\n",
            " 52  char_freq_%24               4601 non-null   float64\n",
            " 53  char_freq_%23               4601 non-null   float64\n",
            " 54  capital_run_length_average  4601 non-null   float64\n",
            " 55  capital_run_length_longest  4601 non-null   int64  \n",
            " 56  capital_run_length_total    4601 non-null   int64  \n",
            " 57  class                       4601 non-null   int64  \n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIaSUH-eytgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d53b4d73-caf7-4c0d-8202-95bf273ba589"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "word_freq_make                0\n",
              "word_freq_address             0\n",
              "word_freq_all                 0\n",
              "word_freq_3d                  0\n",
              "word_freq_our                 0\n",
              "word_freq_over                0\n",
              "word_freq_remove              0\n",
              "word_freq_internet            0\n",
              "word_freq_order               0\n",
              "word_freq_mail                0\n",
              "word_freq_receive             0\n",
              "word_freq_will                0\n",
              "word_freq_people              0\n",
              "word_freq_report              0\n",
              "word_freq_addresses           0\n",
              "word_freq_free                0\n",
              "word_freq_business            0\n",
              "word_freq_email               0\n",
              "word_freq_you                 0\n",
              "word_freq_credit              0\n",
              "word_freq_your                0\n",
              "word_freq_font                0\n",
              "word_freq_000                 0\n",
              "word_freq_money               0\n",
              "word_freq_hp                  0\n",
              "word_freq_hpl                 0\n",
              "word_freq_george              0\n",
              "word_freq_650                 0\n",
              "word_freq_lab                 0\n",
              "word_freq_labs                0\n",
              "word_freq_telnet              0\n",
              "word_freq_857                 0\n",
              "word_freq_data                0\n",
              "word_freq_415                 0\n",
              "word_freq_85                  0\n",
              "word_freq_technology          0\n",
              "word_freq_1999                0\n",
              "word_freq_parts               0\n",
              "word_freq_pm                  0\n",
              "word_freq_direct              0\n",
              "word_freq_cs                  0\n",
              "word_freq_meeting             0\n",
              "word_freq_original            0\n",
              "word_freq_project             0\n",
              "word_freq_re                  0\n",
              "word_freq_edu                 0\n",
              "word_freq_table               0\n",
              "word_freq_conference          0\n",
              "char_freq_%3B                 0\n",
              "char_freq_%28                 0\n",
              "char_freq_%5B                 0\n",
              "char_freq_%21                 0\n",
              "char_freq_%24                 0\n",
              "char_freq_%23                 0\n",
              "capital_run_length_average    0\n",
              "capital_run_length_longest    0\n",
              "capital_run_length_total      0\n",
              "class                         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lnlDdlqyWRl",
        "colab_type": "text"
      },
      "source": [
        "4. Tidying the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxt4lArlzugl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42cfba2a-1610-46a5-990c-875d98999530"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4601, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n147MWZRywo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1b87ab7b-78ff-49a7-912b-6909d42f3605"
      },
      "source": [
        "df.duplicated(subset=None, keep='first')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       False\n",
              "1       False\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "        ...  \n",
              "4596    False\n",
              "4597    False\n",
              "4598    False\n",
              "4599    False\n",
              "4600    False\n",
              "Length: 4601, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYcS8e7H1yO6",
        "colab_type": "text"
      },
      "source": [
        "Outlier detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5T6R0lznfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "177c220f-6e6a-45e3-9bb8-3bbc2666a44f"
      },
      "source": [
        "# Create detector\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "outlier_detector = EllipticEnvelope(contamination=.1)\n",
        "\n",
        "# Fit detector\n",
        "outlier_detector.fit(df)\n",
        "\n",
        "# Predict outliers\n",
        "outlier_detector.predict(df)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-248.843085999315491 > -266.705553285045994). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-205.740814489980551 > -260.029841431920886). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-211.112090121072328 > -259.110220934536642). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-210.809167859124926 > -255.535448802820667). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-207.294918464204812 > -259.489365935985006). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-194.452039187034785 > -244.795609338410031). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-199.743787913425280 > -246.838431961365075). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-224.336014138904943 > -282.121326503483999). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-221.201225815348863 > -280.152780064546278). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/covariance/_robust_covariance.py:170: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-217.609245805190625 > -276.071674299596623). You may want to try with a higher value of support_fraction (current value: 0.507).\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FNmIA9YArz3",
        "colab_type": "text"
      },
      "source": [
        "Gaussian Naive Bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRQr6IVEA5U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries and datasets to be used in this example\n",
        "#\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbPo4VAi-wN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting our dataset into its attributes and labels\n",
        "# ---\n",
        "# The X variable contains the first four columns of the dataset (i.e. attributes) while y contains the labels.\n",
        "# ---\n",
        "# \n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, 53].values"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i5Zo5HJ-9AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train test split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=4)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyY7sn8qF-ND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d0fdcb1-c90f-455d-c5c7-15caa9b9b2b0"
      },
      "source": [
        "# Instantiate: create object\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Fit\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "acc"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-4e9555b7e0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m--> 208\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0;31m# This is the first call to partial_fit:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;31m# initialize various cumulative counters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m_check_partial_fit_first_call\u001b[0;34m(clf, classes)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# This is the first call to partial_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([0.0000e+00, 2.0000e-03, 3.0000e-03, 5.0000e-03, 6.0000e-03,\n       7.0000e-03, 8.0000e-03, 9.0000e-03, 1.0000e-02, 1.1000e-02,\n       1.2000e-02, 1.3000e-02, 1.4000e-02, 1.5000e-02, 1.6000e-02,\n       1.7000e-02, 1.8000e-02, 1.9000e-02, 2.0000e-02, 2.1000e-02,\n       2.2000e-02, 2.3000e-02, 2.4000e-02, 2.5000e-02, 2.6000e-02,\n       2.7000e-02, 2.8000e-02, 2.9000e-02, 3.0000e-02, 3.1000e-02,\n       3.2000e-02, 3.3000e-02, 3.4000e-02, 3.6000e-02, 3.7000e-02,\n       3.8000e-02, 3.9000e-02, 4.0000e-02, 4.1000e-02, 4.3000e-02,\n       4.4000e-02, 4.5000e-02, 4.6000e-02, 4.7000e-02, 4.8000e-02,\n       4.9000e-02, 5.0000e-02, 5.1000e-02, 5.2000e-02, 5.3000e-02,\n       5.4000e-02, 5.5000e-02, 5.6000e-02, 5.7000e-02, 5.8000e-02,\n       5.9000e-02, 6.1000e-02, 6.2000e-02, 6.3000e-02, 6.4000e-02,\n       6.5000e-02, 6.6000e-02, 6.7000e-02, 6.9000e-02, 7.0000e-02,\n       7.1000e-02, 7.2000e-02, 7.3000e-02, 7.4000e-02, 7.5000e-02,\n       7.6000e-02, 7.7000e-02, 7.8000e-02, 7.9000e-02, 8.0000e-02,\n       8.1000e-02, 8.2000e-02, 8.3000e-02, 8.4000e-02, 8.6000e-02,\n       8.7000e-02, 8.8000e-02, 8.9000e-02, 9.0000e-02, 9.2000e-02,\n       9.4000e-02, 9.5000e-02, 9.6000e-02, 9.7000e-02, 9.9000e-02,\n       1.0200e-01, 1.0300e-01, 1.0400e-01, 1.0500e-01, 1.0600e-01,\n       1.0700e-01, 1.0800e-01, 1.0900e-01, 1.1000e-01, 1.1100e-01,\n       1.1200e-01, 1.1300e-01, 1.1400e-01, 1.1500e-01, 1.1600e-01,\n       1.2000e-01, 1.2200e-01, 1.2300e-01, 1.2400e-01, 1.2500e-01,\n       1.2600e-01, 1.2700e-01, 1.2800e-01, 1.2900e-01, 1.3200e-01,\n       1.3300e-01, 1.3400e-01, 1.3500e-01, 1.3600e-01, 1.3700e-01,\n       1.4000e-01, 1.4100e-01, 1.4200e-01, 1.4300e-01, 1.4400e-01,\n       1.4500e-01, 1.4800e-01, 1.4900e-01, 1.5000e-01, 1.5100e-01,\n       1.5300e-01, 1.5600e-01, 1.5700e-01, 1.5800e-01, 1.5900e-01,\n       1.6100e-01, 1.6200e-01, 1.6400e-01, 1.6500e-01, 1.6600e-01,\n       1.6700e-01, 1.6800e-01, 1.6900e-01, 1.7000e-01, 1.7100e-01,\n       1.7700e-01, 1.7800e-01, 1.8200e-01, 1.8300e-01, 1.8500e-01,\n       1.8600e-01, 1.9000e-01, 1.9400e-01, 1.9900e-01, 2.0200e-01,\n       2.0300e-01, 2.0400e-01, 2.1000e-01, 2.1100e-01, 2.1500e-01,\n       2.1600e-01, 2.1700e-01, 2.2600e-01, 2.2900e-01, 2.3000e-01,\n       2.3100e-01, 2.3200e-01, 2.3300e-01, 2.3500e-01, 2.3600e-01,\n       2.3700e-01, 2.4800e-01, 2.5000e-01, 2.5500e-01, 2.6000e-01,\n       2.6600e-01, 2.6800e-01, 2.7900e-01, 2.8000e-01, 2.8500e-01,\n       2.9000e-01, 2.9300e-01, 2.9400e-01, 3.0400e-01, 3.0700e-01,\n       3.2600e-01, 3.2900e-01, 3.3000e-01, 3.3500e-01, 3.3700e-01,\n       3.4100e-01, 3.4200e-01, 3.4800e-01, 3.4900e-01, 3.5000e-01,\n       3.6500e-01, 3.7100e-01, 3.8000e-01, 3.8100e-01, 3.8400e-01,\n       3.9400e-01, 3.9600e-01, 4.0900e-01, 4.1200e-01, 4.1600e-01,\n       4.3500e-01, 4.3700e-01, 4.3900e-01, 4.4100e-01, 4.4600e-01,\n       4.5000e-01, 4.5400e-01, 4.5900e-01, 4.6000e-01, 4.6500e-01,\n       4.6600e-01, 4.7900e-01, 4.8000e-01, 4.8100e-01, 4.8200e-01,\n       4.8400e-01, 5.0300e-01, 5.0400e-01, 5.0700e-01, 5.1700e-01,\n       5.1800e-01, 5.3000e-01, 5.3900e-01, 5.5500e-01, 5.8200e-01,\n       6.0200e-01, 6.3000e-01, 6.3900e-01, 6.5700e-01, 6.7600e-01,\n       6.8600e-01, 7.5100e-01, 7.6300e-01, 7.7600e-01, 8.3600e-01,\n       8.8900e-01, 9.2500e-01, 9.2800e-01, 9.6900e-01, 9.9800e-01,\n       1.0020e+00, 1.0430e+00, 1.0470e+00, 1.0510e+00, 1.0680e+00,\n       1.0830e+00, 1.0840e+00, 1.1180e+00, 1.1210e+00, 1.1570e+00,\n       1.2330e+00, 1.4030e+00, 1.4680e+00, 1.5030e+00, 1.5600e+00,\n       1.5700e+00, 1.5840e+00, 1.6250e+00, 1.7240e+00, 1.8820e+00,\n       1.9980e+00, 2.2330e+00, 2.2900e+00, 2.5170e+00, 3.8790e+00,\n       4.0080e+00, 6.8960e+00, 7.4070e+00, 1.3129e+01, 1.9829e+01]),)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFmRfESwuBuN",
        "colab_type": "text"
      },
      "source": [
        "Implementing the solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KRisiSnCf5G",
        "colab_type": "text"
      },
      "source": [
        "Multinomial Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NXgRuNlCfDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting\n",
        "train_x, test_x, train_y, test_y = train_test_split(df.drop('class', axis=1),\n",
        "                                                    df['class'],\n",
        "                                                    test_size = 0.4, random_state=6)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Ft1XbzZAN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fitting our modelling\n",
        "\n",
        "model = MultinomialNB().fit(train_x, train_y)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG9vkMRPZI6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66411f42-78dd-4190-b6bb-d09c79960aa0"
      },
      "source": [
        "#evaluating our model\n",
        "predictions = model.predict(test_x)\n",
        "sum(predictions) / len(predictions)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40901683867463334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIgQcdvpaV4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3e3371c-1a39-490c-ead9-213fba32a598"
      },
      "source": [
        "#accuracy\n",
        "accuracy_rate = accuracy_score(test_y, predictions)\n",
        "accuracy_rate"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8104291146116241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPk0Lg3tcvVw",
        "colab_type": "text"
      },
      "source": [
        "changing the columns and sample size to 57"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-AjOy9c5Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:, :-5].values\n",
        "y = df.iloc[:, 45].values"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkS0NGfxiofB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting\n",
        "train_x, test_x, train_y, test_y = train_test_split(df.drop('class', axis=1),\n",
        "                                                    df['class'],\n",
        "                                                    test_size = 0.57, random_state=6)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RAXrsCGchOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f86dcd4-0b58-48a7-fd2b-60bba6bcd3eb"
      },
      "source": [
        "# Instantiate: create object\n",
        "#fitting our modelling\n",
        "\n",
        "model = MultinomialNB().fit(train_x, train_y)\n",
        "\n",
        "\n",
        "#evaluating our model\n",
        "predictions = model.predict(test_x)\n",
        "sum(predictions) / len(predictions)\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4135159273593331"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxUk5HU8jSdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "814eefa5-9ec3-46a1-e620-9baae8744e73"
      },
      "source": [
        "#accuracy\n",
        "accuracy_rate = accuracy_score(test_y, predictions)\n",
        "accuracy_rate"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8154212563262876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MiGxfasi79Q",
        "colab_type": "text"
      },
      "source": [
        "changing the sample size to 73"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5204VZKnjnTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:, 48].values\n",
        "y = df.iloc[:, 48].values"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sye-i1p3aiPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting\n",
        "train_x, test_x, train_y, test_y = train_test_split(df.drop('class', axis=1),\n",
        "                                                    df['class'],\n",
        "                                                    test_size = 0.73, random_state=6)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fpz-2CMjJrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d43272a-763d-48ce-9958-32ab9e316be4"
      },
      "source": [
        "# Instantiate: create object\n",
        "#fitting our modelling\n",
        "\n",
        "model = MultinomialNB().fit(train_x, train_y)\n",
        "\n",
        "\n",
        "#evaluating our model\n",
        "predictions = model.predict(test_x)\n",
        "sum(predictions) / len(predictions)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4135159273593331"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Ll6_QijKIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89ba9012-fba2-4ddd-8c61-5cabe07178cd"
      },
      "source": [
        "#accuracy\n",
        "accuracy_rate = accuracy_score(test_y, predictions)\n",
        "accuracy_rate"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8154212563262876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWxUExy1uQtY",
        "colab_type": "text"
      },
      "source": [
        "Challenging the soultion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msUHIWXakJSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c618d592-3445-44a3-ef10-1495d85596b5"
      },
      "source": [
        "test_x = test_x[test_x.columns[:30]]\n",
        "train_x = train_x[train_x.columns[:30]]\n",
        "\n",
        "# Instantiate: create object\n",
        "#fitting our modelling\n",
        "\n",
        "model = MultinomialNB().fit(train_x, train_y)\n",
        "\n",
        "\n",
        "#evaluating our model\n",
        "predictions = model.predict(test_x)\n",
        "#accuracy\n",
        "accuracy_rate = accuracy_score(test_y, predictions)\n",
        "accuracy_rate\n"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.808573980351295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77oLqsCKuUKB",
        "colab_type": "text"
      },
      "source": [
        "Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfC4tziwnxxL",
        "colab_type": "text"
      },
      "source": [
        "The accuracy is at its at 0.8154212563262876\n",
        "\n",
        "Gaussian naive bayes and bernoulli did not work so i had to disregard them and only use multinomial\n",
        "\n",
        "changing the sample size changed the prediction results where more samples used gave better prediction\n"
      ]
    }
  ]
}